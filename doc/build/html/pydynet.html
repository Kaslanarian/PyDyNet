<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pydynet package &mdash; PyDyNet 0.0.1 文档</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/translations.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> PyDyNet
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">pydynet package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-pydynet.dataloader">pydynet.dataloader module</a></li>
<li><a class="reference internal" href="#module-pydynet.functional">pydynet.functional module</a></li>
<li><a class="reference internal" href="#module-pydynet.nn">pydynet.nn module</a></li>
<li><a class="reference internal" href="#module-pydynet.optimizer">pydynet.optimizer module</a><ul>
<li><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-pydynet.tensor">pydynet.tensor module</a></li>
<li><a class="reference internal" href="#module-pydynet">Module contents</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyDyNet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>pydynet package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/pydynet.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pydynet-package">
<h1>pydynet package<a class="headerlink" href="#pydynet-package" title="永久链接至标题"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="永久链接至标题"></a></h2>
</section>
<section id="module-pydynet.dataloader">
<span id="pydynet-dataloader-module"></span><h2>pydynet.dataloader module<a class="headerlink" href="#module-pydynet.dataloader" title="永久链接至标题"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pydynet.dataloader.train_loader">
<span class="sig-prename descclassname"><span class="pre">pydynet.dataloader.</span></span><span class="sig-name descname"><span class="pre">train_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span></span></span><a class="headerlink" href="#pydynet.dataloader.train_loader" title="永久链接至目标"></a></dt>
<dd><p>对训练集数据进行划分，实现mini-batch机制。</p>
<p>当测试数据较大时也可用该函数进行处理。</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy.ndarray</em>) – 训练集特征数据</p></li>
<li><p><strong>y</strong> (<em>numpy.ndarray</em>) – 训练集标签数据</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – 划分数据的大小</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否打乱，默认不打乱</p></li>
</ul>
</dd>
<dt class="field-even">返回</dt>
<dd class="field-even"><p>以(特征数据, 标签数据)为单位的列表</p>
</dd>
<dt class="field-odd">返回类型</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loader</span> <span class="o">=</span> <span class="n">train_loader</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
<span class="go">[[0 1 2]</span>
<span class="go">[3 4 5]] [0  0]</span>
<span class="go">[[ 6  7  8]</span>
<span class="go">[ 9 10 11]] [1  1]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-pydynet.functional">
<span id="pydynet-functional-module"></span><h2>pydynet.functional module<a class="headerlink" href="#module-pydynet.functional" title="永久链接至标题"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.concatenate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">concatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.concatenate" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.Tensor</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.concatenate.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.concatenate.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.concatenate.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.concatenate.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.conv1d">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">conv1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.conv1d" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.conv2d">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.conv2d" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.cross_entropy_loss">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">cross_entropy_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.cross_entropy_loss" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.exp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.exp" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.exp.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.exp.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.exp.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.exp.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.im2col1d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">im2col1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.im2col1d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.im2col1d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.im2col1d.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.im2col1d.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.im2col1d.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.im2col2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">im2col2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.im2col2d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.im2col2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.im2col2d.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.im2col2d.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.im2col2d.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.leaky_relu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">leaky_relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.leaky_relu" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.leaky_relu.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.leaky_relu.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.leaky_relu.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.leaky_relu.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.log">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.log" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.log.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.log.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.log.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.log.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.log_softmax">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">log_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.log_softmax" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.max_pool1d">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">max_pool1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.max_pool1d" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.max_pool2d">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">max_pool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.max_pool2d" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.mse_loss">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.mse_loss" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.nll_loss">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">nll_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.nll_loss" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.pad1d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">pad1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.pad1d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.pad1d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.pad1d.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.pad1d.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.pad1d.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.pad2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">pad2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.pad2d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.pad2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.pad2d.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.pad2d.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.pad2d.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.relu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.relu" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.relu.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.relu.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.relu.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.relu.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.sigmoid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.sigmoid" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.sigmoid.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.sigmoid.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.sigmoid.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.sigmoid.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.softmax">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.softmax" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.sqrt">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">sqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.sqrt" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.functional.square">
<span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">square</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.square" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.functional.tanh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.functional.</span></span><span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.functional.tanh" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.tanh.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.tanh.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.functional.tanh.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.functional.tanh.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-pydynet.nn">
<span id="pydynet-nn-module"></span><h2>pydynet.nn module<a class="headerlink" href="#module-pydynet.nn" title="永久链接至标题"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.BatchNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">BatchNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.99</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.BatchNorm" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.BatchNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.BatchNorm.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Conv1d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Conv1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Conv1d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Conv1d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Conv1d.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Conv2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Conv2d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Conv2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Conv2d.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.CrossEntropyLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">CrossEntropyLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.CrossEntropyLoss" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.MSELoss" title="pydynet.nn.MSELoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.MSELoss</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.CrossEntropyLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.CrossEntropyLoss.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Dropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Dropout" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Dropout.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.Dropout.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Embedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Embedding" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Embedding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.Embedding.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.GRU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">GRU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.GRU" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.GRU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(None,</span> <span class="pre">None)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.GRU.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.LSTM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">LSTM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.LSTM" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.LSTM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(None,</span> <span class="pre">None)</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.LSTM.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.LeakyReLU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">LeakyReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.LeakyReLU" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.LeakyReLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.LeakyReLU.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Linear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Linear" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Linear.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Linear.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.MSELoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">MSELoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.MSELoss" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.MSELoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.MSELoss.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.MaxPool1d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">MaxPool1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.MaxPool1d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.MaxPool1d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.MaxPool1d.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.MaxPool2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">MaxPool2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.MaxPool2d" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.MaxPool2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.MaxPool2d.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Module">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Module</span></span><a class="headerlink" href="#pydynet.nn.Module" title="永久链接至目标"></a></dt>
<dd><p>基类：<code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Module.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Module.eval" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Module.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.Module.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Module.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Module.parameters" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Module.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Module.train" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.NLLLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">NLLLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.NLLLoss" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.MSELoss" title="pydynet.nn.MSELoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.MSELoss</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.NLLLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></span><a class="headerlink" href="#pydynet.nn.NLLLoss.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Parameter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Parameter" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.Tensor</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.RNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">RNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinearity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.RNN" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<p>单层RNN，不像Pytorch那样可以指定num_layers进行多层堆叠，我们的RNN是单层可双向的，
如果要搭建多层RNN:</p>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
class MultiLayerRNN(Module):</p>
<blockquote>
<div><dl class="simple">
<dt>def __init__(self):</dt><dd><p>super().__init__()
self.rnn1 = RNN(…)
self.rnn2 = RNN(…)
…</p>
</dd>
<dt>def forward(x, h=None):</dt><dd><p>x = self.rnn1(x, h)
return self.rnn2(x)</p>
</dd>
</dl>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.RNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(None,</span> <span class="pre">None)</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.RNN.forward" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>if batch_first:</dt><dd><p>x.shape : (batch, seq_len, input_size)
h.shape : (batch, seq_len, hidden_size)</p>
</dd>
<dt>else:</dt><dd><p>x.shape : (seq_len, batch, input_size)
h.shape : (seq_len, batch, hidden_size)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.ReLU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">ReLU</span></span><a class="headerlink" href="#pydynet.nn.ReLU" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Sigmoid" title="pydynet.nn.Sigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Sigmoid</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.ReLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.ReLU.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Sigmoid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Sigmoid</span></span><a class="headerlink" href="#pydynet.nn.Sigmoid" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Module" title="pydynet.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Module</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Sigmoid.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Sigmoid.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.nn.Tanh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.nn.</span></span><span class="sig-name descname"><span class="pre">Tanh</span></span><a class="headerlink" href="#pydynet.nn.Tanh" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.nn.Sigmoid" title="pydynet.nn.Sigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.nn.Sigmoid</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.nn.Tanh.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.nn.Tanh.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-pydynet.optimizer">
<span id="pydynet-optimizer-module"></span><h2>pydynet.optimizer module<a class="headerlink" href="#module-pydynet.optimizer" title="永久链接至标题"></a></h2>
<p>优化器类，我们目前实现了</p>
<ul class="simple">
<li><p>SGD;</p></li>
<li><p>Momentum;</p></li>
<li><p>Adagrad;</p></li>
<li><p>Adadelta;</p></li>
<li><p>Adam.</p></li>
</ul>
<section id="reference">
<h3>Reference<a class="headerlink" href="#reference" title="永久链接至标题"></a></h3>
<p>论文: <a class="reference external" href="https://arxiv.org/abs/1609.04747">https://arxiv.org/abs/1609.04747</a>;</p>
<p>博客: <a class="reference external" href="https://welts.xyz/2021/08/20/gd/">https://welts.xyz/2021/08/20/gd/</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="pydynet.optimizer.Adadelta">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.optimizer.</span></span><span class="sig-name descname"><span class="pre">Adadelta</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adadelta" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.optimizer.Adagrad" title="pydynet.optimizer.Adagrad"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.optimizer.Adagrad</span></code></a></p>
<p>Adadelta下降法</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>tuple</em>) – 待优化参数元组;</p></li>
<li><p><strong>lr</strong> (<em>float</em>) – 学习率;</p></li>
<li><p><strong>gamma</strong> (<em>float</em><em>, </em><em>default=0.9</em>) – 滑动系数 <span class="math notranslate nohighlight">\(\gamma\)</span>，默认0.9;</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>default=0.</em>) – 权重衰减系数.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Adadelta.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adadelta.step" title="永久链接至目标"></a></dt>
<dd><p>对所有参数进行上式的更新.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Adadelta.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adadelta.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>针对self.params梯度清零.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.optimizer.Adagrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.optimizer.</span></span><span class="sig-name descname"><span class="pre">Adagrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adagrad" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.optimizer.SGD" title="pydynet.optimizer.SGD"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.optimizer.SGD</span></code></a></p>
<p>Adagrad下降法</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>tuple</em>) – 待优化参数元组;</p></li>
<li><p><strong>lr</strong> (<em>float</em>) – 学习率;</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>default=0.</em>) – 权重衰减系数.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Adagrad.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adagrad.step" title="永久链接至目标"></a></dt>
<dd><p>对所有参数进行上式的更新.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Adagrad.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adagrad.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>针对self.params梯度清零.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.optimizer.Adam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.optimizer.</span></span><span class="sig-name descname"><span class="pre">Adam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adam" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.optimizer.SGD" title="pydynet.optimizer.SGD"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.optimizer.SGD</span></code></a></p>
<p>Adam下降法</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>tuple</em>) – 待优化参数元组;</p></li>
<li><p><strong>lr</strong> (<em>float</em>) – 学习率;</p></li>
<li><p><strong>beta1</strong> (<em>float</em><em>, </em><em>default=0.9</em>) – Adam参数1，默认0.9;</p></li>
<li><p><strong>beta2</strong> (<em>float</em><em>, </em><em>default=0.999</em>) – Adam参数2，默认0.999;</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>default=0.</em>) – 权重衰减系数.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Adam.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adam.step" title="永久链接至目标"></a></dt>
<dd><p>对所有参数进行上式的更新.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Adam.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Adam.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>针对self.params梯度清零.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.optimizer.Momentum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.optimizer.</span></span><span class="sig-name descname"><span class="pre">Momentum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Momentum" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.optimizer.SGD" title="pydynet.optimizer.SGD"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.optimizer.SGD</span></code></a></p>
<p>带动量的梯度下降</p>
<div class="math notranslate nohighlight">
\[\begin{split}v_t &amp;= \gamma v_{t-1}+\eta\nabla_{\theta}J(\theta) \\
\theta &amp;= \theta-v_t\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>tuple</em>) – 待优化参数元组;</p></li>
<li><p><strong>lr</strong> (<em>float</em>) – 学习率;</p></li>
<li><p><strong>momentum</strong> (<em>float</em><em>, </em><em>default=0.5</em>) – 动量系数;</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>default=0.</em>) – 权重衰减系数.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Momentum.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Momentum.step" title="永久链接至目标"></a></dt>
<dd><p>对所有参数进行上式的更新.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.Momentum.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.Momentum.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>针对self.params梯度清零.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.optimizer.SGD">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.optimizer.</span></span><span class="sig-name descname"><span class="pre">SGD</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.SGD" title="永久链接至目标"></a></dt>
<dd><p>基类：<code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>批梯度下降优化器:</p>
<div class="math notranslate nohighlight">
\[\theta=\theta-\eta\cdot\nabla_{\theta}J(\theta;x^{(i:i+n)}, y^{(i:i+n)})\]</div>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>tuple</em>) – 待优化参数元组;</p></li>
<li><p><strong>lr</strong> (<em>float</em>) – 学习率;</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>default=0.</em>) – 权重衰减系数.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.SGD.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.SGD.step" title="永久链接至目标"></a></dt>
<dd><p>对所有参数进行上式的更新.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.optimizer.SGD.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.optimizer.SGD.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>针对self.params梯度清零.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="module-pydynet.tensor">
<span id="pydynet-tensor-module"></span><h2>pydynet.tensor module<a class="headerlink" href="#module-pydynet.tensor" title="永久链接至标题"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.BinaryOperator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">BinaryOperator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.BinaryOperator" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.Tensor</span></code></a></p>
<p>二元运算算子的基类，将一个一元函数抽象成类</p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.BinaryOperator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.BinaryOperator.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.BinaryOperator.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.BinaryOperator.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.Graph">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">Graph</span></span><a class="headerlink" href="#pydynet.tensor.Graph" title="永久链接至目标"></a></dt>
<dd><p>基类：<code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>计算图，全局共用一个动态计算图</p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Graph.add_node">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">add_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Graph.add_node" title="永久链接至目标"></a></dt>
<dd><p>添加静态图节点</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Graph.clear">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">clear</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Graph.clear" title="永久链接至目标"></a></dt>
<dd><p>清空计算图</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Graph.free_graph">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">free_graph</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Graph.free_graph" title="永久链接至目标"></a></dt>
<dd><p>释放计算图，和clear的区别在于我们不会删除叶子节点，
这一点和PyTorch类似。</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.tensor.Graph.node_list">
<span class="sig-name descname"><span class="pre">node_list</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[]</span></em><a class="headerlink" href="#pydynet.tensor.Graph.node_list" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">Tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor" title="永久链接至目标"></a></dt>
<dd><p>基类：<code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>将数据(NumPy数组)包装成可微分张量</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>ndarray</em>) – 张量数据，只要是np.array能够转换的数据;</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否需要求梯度;</p></li>
<li><p><strong>dtype</strong> (<em>default=None</em>) – 数据类型，和numpy数组的dtype等价</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.data">
<span class="sig-name descname"><span class="pre">data</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.data" title="永久链接至目标"></a></dt>
<dd><p>核心数据，为NumPy数组;</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.requires_grad">
<span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.requires_grad" title="永久链接至目标"></a></dt>
<dd><p>是否需要求梯度;</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.grad">
<span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.grad" title="永久链接至目标"></a></dt>
<dd><p>梯度数据，为和data相同形状的数组(初始化为全0);</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.next">
<span class="sig-name descname"><span class="pre">next</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.next" title="永久链接至目标"></a></dt>
<dd><p>下游节点列表；</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor">Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.last">
<span class="sig-name descname"><span class="pre">last</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.last" title="永久链接至目标"></a></dt>
<dd><p>上游节点列表.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor">Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.T">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">T</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.T" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.astype">
<span class="sig-name descname"><span class="pre">astype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.astype" title="永久链接至目标"></a></dt>
<dd><p>类型转换，我们不允许可求导节点的类型转换</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.backward" title="永久链接至目标"></a></dt>
<dd><p>以节点为输出进行反向传播</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否保留计算图</p>
</dd>
</dl>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pydynet.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">5.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.build_edge">
<span class="sig-name descname"><span class="pre">build_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.build_edge" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.dtype" title="永久链接至目标"></a></dt>
<dd><p>张量的数据类型，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;int64&#39;)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.equal">
<span class="sig-name descname"><span class="pre">equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.equal" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.inequal">
<span class="sig-name descname"><span class="pre">inequal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.inequal" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.is_leaf">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_leaf</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.is_leaf" title="永久链接至目标"></a></dt>
<dd><p>需要求导且无上游节点的节点为叶节点.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>判断是否为叶节点</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.max">
<span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.max" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.mean" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.ndim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ndim</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.ndim" title="永久链接至目标"></a></dt>
<dd><p>张量的维度，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">ndim</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.reshape">
<span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">new_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.reshape" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.shape" title="永久链接至目标"></a></dt>
<dd><p>张量的形状，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">size</span></span><a class="headerlink" href="#pydynet.tensor.Tensor.size" title="永久链接至目标"></a></dt>
<dd><p>张量的元素个数，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">size</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.sum">
<span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.sum" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.transpose">
<span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.transpose" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.Tensor.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.Tensor.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>梯度归零</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.UnaryOperator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">UnaryOperator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.UnaryOperator" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.Tensor</span></code></a></p>
<p>一元运算算子的基类，将一个一元函数抽象成类</p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.UnaryOperator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.UnaryOperator.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.UnaryOperator.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.UnaryOperator.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.abs">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.abs" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>绝对值算子，在Tensor类中进行重载</p>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.add" title="pydynet.tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></dt><dd><p>加法算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.abs.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.abs.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.abs.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.abs.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.add">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.add" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.BinaryOperator" title="pydynet.tensor.BinaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.BinaryOperator</span></code></a></p>
<p>加法算子</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># 在Tensor类中进行了重载，所以也可以写成</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.add.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.add.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.add.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.add.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.div">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.div" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.BinaryOperator" title="pydynet.tensor.BinaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.BinaryOperator</span></code></a></p>
<p>除法算子，在Tensor类中进行重载</p>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.add" title="pydynet.tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></dt><dd><p>加法算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.div.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.div.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.div.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.div.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.get_slice">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">get_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.get_slice" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>切片算子，为Tensor类提供索引和切片接口</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span>
<span class="go">        np.arange(12).reshape(3, 4).astype(float),</span>
<span class="go">        requires_grad=True,</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">[[1. 1. 0. 0.]</span>
<span class="go"> [1. 1. 0. 0.]</span>
<span class="go"> [0. 0. 0. 0.]]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.get_slice.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.get_slice.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.get_slice.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.get_slice.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.matmul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.matmul" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.BinaryOperator" title="pydynet.tensor.BinaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.BinaryOperator</span></code></a></p>
<p>矩阵乘法算子，在Tensor类中进行重载，张量的矩阵乘法遵从NumPy Matmul的规则.</p>
<p><a class="reference external" href="https://welts.xyz/2022/04/26/broadcast/">https://welts.xyz/2022/04/26/broadcast/</a></p>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.add" title="pydynet.tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></dt><dd><p>加法算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.matmul.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.matmul.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.matmul.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.matmul.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.max">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.max" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>求最大值算子，在Tensor类中扩展为类方法</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>None</em>) – 求最大值方向(轴)</p></li>
<li><p><strong>keepdims</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否保留原来维度</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.sum" title="pydynet.tensor.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code></a></dt><dd><p>求和算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.max.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.max.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.max.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.max.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.mean">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.mean" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>求均值算子，在Tensor类中扩展为类方法</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>None</em>) – 求均值方向(轴)</p></li>
<li><p><strong>keepdims</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否保留原来维度</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.sum" title="pydynet.tensor.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code></a></dt><dd><p>求和算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.mean.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.mean.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.mean.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.mean.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.mul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">mul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.mul" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.BinaryOperator" title="pydynet.tensor.BinaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.BinaryOperator</span></code></a></p>
<p>元素级乘法算子，在Tensor类中进行重载</p>
<p class="rubric">示例</p>
<p><code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">x</span> <span class="pre">=</span> <span class="pre">Tensor([1.,</span> <span class="pre">2.])</span>
<span class="pre">y</span> <span class="pre">=</span> <span class="pre">Tensor([2.,</span> <span class="pre">3.])</span>
<span class="pre">z</span> <span class="pre">=</span> <span class="pre">mul(x,</span> <span class="pre">y)</span> <span class="pre">#</span> <span class="pre">[2,</span> <span class="pre">6]</span>
<span class="pre">`</span></code></p>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.add" title="pydynet.tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></dt><dd><p>加法算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.mul.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.mul.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.mul.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.mul.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.tensor.ones">
<span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">ones</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.ones" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.pow">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">pow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.pow" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.BinaryOperator" title="pydynet.tensor.BinaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.BinaryOperator</span></code></a></p>
<p>幂运算算子，在Tensor类中进行重载</p>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.add" title="pydynet.tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></dt><dd><p>加法算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.pow.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.pow.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.pow.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.pow.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.tensor.rand">
<span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">rand</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.rand" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.tensor.randn">
<span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">randn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.randn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.reshape">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.reshape" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>张量形状变换算子，在Tensor中进行重载</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><p><strong>new_shape</strong> (<em>tuple</em>) – 变换后的形状，用法同NumPy</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.reshape.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.reshape.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.reshape.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.reshape.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.sub">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">sub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.sub" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.BinaryOperator" title="pydynet.tensor.BinaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.BinaryOperator</span></code></a></p>
<p>减法算子，在Tensor类中进行重载</p>
<div class="admonition seealso">
<p class="admonition-title">参见</p>
<dl class="simple">
<dt><a class="reference internal" href="#pydynet.tensor.add" title="pydynet.tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></dt><dd><p>加法算子</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.sub.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.sub.forward" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.sub.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.sub.grad_fn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.sum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.sum" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>求和算子，在Tensor类中扩展为类方法</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>None</em>) – 求和方向(轴)</p></li>
<li><p><strong>keepdims</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否保留原来维度</p></li>
</ul>
</dd>
</dl>
<p class="rubric">示例</p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>python
x = Tensor(</p>
<blockquote>
<div><p>[[1, 2, 3],
[4, 5, 6]]</p>
</div></blockquote>
<p>)
s1 = x.sum(0) # [5, 7, 9]
s2 = x.sum(1) # [6, 15]
s3 = sum(x, keepdims=True) # [[21]]
<a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.sum.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.sum.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.sum.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.sum.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pydynet.tensor.transpose">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.transpose" title="永久链接至目标"></a></dt>
<dd><p>基类：<a class="reference internal" href="#pydynet.tensor.UnaryOperator" title="pydynet.tensor.UnaryOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pydynet.tensor.UnaryOperator</span></code></a></p>
<p>张量转置算子，在Tensor中进行重载(Tensor.T和Tensor.transpose)</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><p><strong>axes</strong> (<em>tuple</em>) – 转置的轴变换，用法同NumPy</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.transpose.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.transpose.forward" title="永久链接至目标"></a></dt>
<dd><p>前向传播函数，参数为Tensor，返回的是NumPy数组</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.tensor.transpose.grad_fn">
<span class="sig-name descname"><span class="pre">grad_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pydynet.tensor.Tensor" title="pydynet.tensor.Tensor"><span class="pre">pydynet.tensor.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#pydynet.tensor.transpose.grad_fn" title="永久链接至目标"></a></dt>
<dd><dl class="simple">
<dt>x<span class="classifier">Tensor</span></dt><dd><p>上游节点</p>
</dd>
<dt>grad<span class="classifier">ndarray</span></dt><dd><p>下游流入该节点的梯度</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.tensor.uniform">
<span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.uniform" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.tensor.zeros">
<span class="sig-prename descclassname"><span class="pre">pydynet.tensor.</span></span><span class="sig-name descname"><span class="pre">zeros</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.tensor.zeros" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</section>
<section id="module-pydynet">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pydynet" title="永久链接至标题"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pydynet.Tensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pydynet.</span></span><span class="sig-name descname"><span class="pre">Tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor" title="永久链接至目标"></a></dt>
<dd><p>基类：<code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>将数据(NumPy数组)包装成可微分张量</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>ndarray</em>) – 张量数据，只要是np.array能够转换的数据;</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否需要求梯度;</p></li>
<li><p><strong>dtype</strong> (<em>default=None</em>) – 数据类型，和numpy数组的dtype等价</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.Tensor.data">
<span class="sig-name descname"><span class="pre">data</span></span><a class="headerlink" href="#pydynet.Tensor.data" title="永久链接至目标"></a></dt>
<dd><p>核心数据，为NumPy数组;</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.Tensor.requires_grad">
<span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#pydynet.Tensor.requires_grad" title="永久链接至目标"></a></dt>
<dd><p>是否需要求梯度;</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.Tensor.grad">
<span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#pydynet.Tensor.grad" title="永久链接至目标"></a></dt>
<dd><p>梯度数据，为和data相同形状的数组(初始化为全0);</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.Tensor.next">
<span class="sig-name descname"><span class="pre">next</span></span><a class="headerlink" href="#pydynet.Tensor.next" title="永久链接至目标"></a></dt>
<dd><p>下游节点列表；</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#pydynet.Tensor" title="pydynet.Tensor">Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="pydynet.Tensor.last">
<span class="sig-name descname"><span class="pre">last</span></span><a class="headerlink" href="#pydynet.Tensor.last" title="永久链接至目标"></a></dt>
<dd><p>上游节点列表.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="#pydynet.Tensor" title="pydynet.Tensor">Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="pydynet.Tensor.T">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">T</span></span><a class="headerlink" href="#pydynet.Tensor.T" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.astype">
<span class="sig-name descname"><span class="pre">astype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.astype" title="永久链接至目标"></a></dt>
<dd><p>类型转换，我们不允许可求导节点的类型转换</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.backward" title="永久链接至目标"></a></dt>
<dd><p>以节点为输出进行反向传播</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><p><strong>retain_graph</strong> (<em>bool</em><em>, </em><em>default=False</em>) – 是否保留计算图</p>
</dd>
</dl>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pydynet.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">5.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.build_edge">
<span class="sig-name descname"><span class="pre">build_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.build_edge" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.Tensor.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#pydynet.Tensor.dtype" title="永久链接至目标"></a></dt>
<dd><p>张量的数据类型，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;int64&#39;)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.equal">
<span class="sig-name descname"><span class="pre">equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.equal" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.inequal">
<span class="sig-name descname"><span class="pre">inequal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.inequal" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.Tensor.is_leaf">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_leaf</span></span><a class="headerlink" href="#pydynet.Tensor.is_leaf" title="永久链接至目标"></a></dt>
<dd><p>需要求导且无上游节点的节点为叶节点.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>判断是否为叶节点</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.max">
<span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.max" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.mean" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.Tensor.ndim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ndim</span></span><a class="headerlink" href="#pydynet.Tensor.ndim" title="永久链接至目标"></a></dt>
<dd><p>张量的维度，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">ndim</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.reshape">
<span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">new_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.reshape" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.Tensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#pydynet.Tensor.shape" title="永久链接至目标"></a></dt>
<dd><p>张量的形状，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pydynet.Tensor.size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">size</span></span><a class="headerlink" href="#pydynet.Tensor.size" title="永久链接至目标"></a></dt>
<dd><p>张量的元素个数，用法同NumPy.</p>
<p class="rubric">示例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pydynet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">size</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.sum">
<span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.sum" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.transpose">
<span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.transpose" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pydynet.Tensor.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.Tensor.zero_grad" title="永久链接至目标"></a></dt>
<dd><p>梯度归零</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.ones">
<span class="sig-prename descclassname"><span class="pre">pydynet.</span></span><span class="sig-name descname"><span class="pre">ones</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.ones" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.rand">
<span class="sig-prename descclassname"><span class="pre">pydynet.</span></span><span class="sig-name descname"><span class="pre">rand</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.rand" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.randn">
<span class="sig-prename descclassname"><span class="pre">pydynet.</span></span><span class="sig-name descname"><span class="pre">randn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.randn" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.uniform">
<span class="sig-prename descclassname"><span class="pre">pydynet.</span></span><span class="sig-name descname"><span class="pre">uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.uniform" title="永久链接至目标"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pydynet.zeros">
<span class="sig-prename descclassname"><span class="pre">pydynet.</span></span><span class="sig-name descname"><span class="pre">zeros</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pydynet.zeros" title="永久链接至目标"></a></dt>
<dd></dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, Welt Xing.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>